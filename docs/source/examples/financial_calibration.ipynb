{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Risk Assessment: Credit Scoring Calibration\n",
    "\n",
    "This example demonstrates rank-preserving calibration for financial risk assessment using simulated credit data. We'll show how credit scoring models need calibration when deployed across different market segments with varying risk profiles.\n",
    "\n",
    "## Financial Motivation\n",
    "\n",
    "Credit scoring models face several calibration challenges:\n",
    "- **Market segment shifts**: Models trained on one population may be poorly calibrated for others\n",
    "- **Economic conditions**: Default rates vary with economic cycles\n",
    "- **Portfolio composition**: Different lending strategies lead to different risk distributions\n",
    "- **Regulatory requirements**: Basel III and CECL require well-calibrated probability of default estimates\n",
    "\n",
    "Rank-preserving calibration maintains credit ranking while adjusting absolute probabilities to match target portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our calibration package - proper imports\n",
    "from rank_preserving_calibration import calibrate_dykstra\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette([\"#2ecc71\", \"#e74c3c\", \"#f39c12\"])  # Green, Red, Orange\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Credit Dataset Creation\n",
    "\n",
    "We'll create a realistic credit dataset with multiple risk segments to simulate real-world credit portfolio management scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üè¶ CREATING SYNTHETIC CREDIT DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create realistic credit features\n",
    "n_samples = 3000\n",
    "n_features = 15\n",
    "\n",
    "# Generate base dataset with class imbalance (most loans don't default)\n",
    "X_base, y_base = make_classification(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    n_classes=3,  # Good, Moderate Risk, High Risk\n",
    "    n_clusters_per_class=2,\n",
    "    class_sep=1.2,\n",
    "    weights=[0.7, 0.2, 0.1],  # Most customers are good credit\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create feature names\n",
    "feature_names = [\n",
    "    'credit_score', 'income', 'debt_to_income', 'employment_years',\n",
    "    'loan_amount', 'payment_history', 'utilization_rate', 'inquiries',\n",
    "    'accounts_open', 'delinquencies', 'public_records', 'age',\n",
    "    'education_level', 'housing_status', 'geographic_risk'\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X_base, columns=feature_names)\n",
    "df['risk_class'] = y_base\n",
    "\n",
    "# Add realistic transformations to make it look like credit data\n",
    "df['credit_score'] = (df['credit_score'] * 100 + 650).clip(300, 850).astype(int)\n",
    "df['income'] = np.exp(df['income'] * 0.5 + 10).clip(20000, 200000).astype(int)\n",
    "df['debt_to_income'] = (df['debt_to_income'] * 0.2 + 0.3).clip(0, 1)\n",
    "df['employment_years'] = (df['employment_years'] * 3 + 5).clip(0, 40).astype(int)\n",
    "df['loan_amount'] = (df['loan_amount'] * 50000 + 25000).clip(1000, 500000).astype(int)\n",
    "\n",
    "print(f\"Dataset created with {len(df)} samples and {len(feature_names)} features\")\n",
    "print(\"Risk class distribution:\")\n",
    "risk_labels = ['Good Credit (0)', 'Moderate Risk (1)', 'High Risk (2)']\n",
    "for i, label in enumerate(risk_labels):\n",
    "    count = np.sum(y_base == i)\n",
    "    pct = count / len(y_base) * 100\n",
    "    print(f\"  {label}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# Show sample of the data\n",
    "print(\"\\nSample of generated credit data:\")\n",
    "display_cols = ['credit_score', 'income', 'debt_to_income', 'loan_amount', 'risk_class']\n",
    "print(df[display_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Initial Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df[feature_names].values\n",
    "y = df['risk_class'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"üéØ TRAINING CREDIT RISK MODEL\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Train gradient boosting model (common in finance)\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get predictions and probabilities\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_proba = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Multi-class AUC (one-vs-rest)\n",
    "auc_scores = []\n",
    "for i in range(3):\n",
    "    y_binary = (y_test == i).astype(int)\n",
    "    if len(np.unique(y_binary)) > 1:  # Only calculate if both classes exist\n",
    "        auc = roc_auc_score(y_binary, y_proba[:, i])\n",
    "        auc_scores.append(auc)\n",
    "        print(f\"AUC for class {i} ({risk_labels[i]}): {auc:.3f}\")\n",
    "\n",
    "mean_auc = np.mean(auc_scores) if auc_scores else 0\n",
    "print(\"\\nOverall model performance:\")\n",
    "print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "print(f\"  Mean AUC: {mean_auc:.3f}\")\n",
    "print(f\"  Test samples: {len(y_test)}\")\n",
    "\n",
    "# Show current probability distributions\n",
    "current_marginals = np.mean(y_proba, axis=0)\n",
    "print(\"\\nCurrent model probability marginals:\")\n",
    "for i, (label, marginal) in enumerate(zip(risk_labels, current_marginals, strict=False)):\n",
    "    print(f\"  {label}: {marginal:.3f} ({marginal*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Economic Scenario and Target Portfolio\n",
    "\n",
    "We'll simulate a scenario where economic conditions change, requiring the model to be recalibrated for a different risk environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà ECONOMIC SCENARIO ANALYSIS\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Simulate economic downturn scenario with increased defaults\n",
    "# Based on historical credit loss data during recessions\n",
    "recession_risk_distribution = np.array([\n",
    "    0.55,   # Good Credit: Reduced from 70% to 55%\n",
    "    0.30,   # Moderate Risk: Increased from 20% to 30%\n",
    "    0.15    # High Risk: Increased from 10% to 15%\n",
    "])\n",
    "\n",
    "print(\"üìä SCENARIO: Economic Downturn Portfolio Rebalancing\")\n",
    "print(\"Target risk distribution reflects:\")\n",
    "print(\"  ‚Ä¢ Increased unemployment affecting credit quality\")\n",
    "print(\"  ‚Ä¢ Business cycle impact on default rates\")\n",
    "print(\"  ‚Ä¢ Regulatory stress testing requirements\")\n",
    "print(\"  ‚Ä¢ Portfolio-specific risk appetite changes\")\n",
    "\n",
    "print(\"\\nTarget portfolio composition:\")\n",
    "for i, (label, target_pct) in enumerate(zip(risk_labels, recession_risk_distribution, strict=False)):\n",
    "    current_pct = current_marginals[i]\n",
    "    change = target_pct - current_pct\n",
    "    direction = \"‚Üë\" if change > 0 else \"‚Üì\" if change < 0 else \"‚Üí\"\n",
    "    print(f\"  {label}: {target_pct:.1%} (change: {change:+.1%} {direction})\")\n",
    "\n",
    "# Business justification\n",
    "print(\"\\nüíº BUSINESS JUSTIFICATION:\")\n",
    "justifications = [\n",
    "    \"CECL accounting requires forward-looking loss estimates\",\n",
    "    \"Basel III stress testing mandates adverse scenario modeling\",\n",
    "    \"Economic indicators suggest increased default risk\",\n",
    "    \"Portfolio rebalancing to maintain target risk-adjusted returns\",\n",
    "    \"Regulatory examiner expectations for downturn preparedness\"\n",
    "]\n",
    "\n",
    "for justification in justifications:\n",
    "    print(f\"   ‚Ä¢ {justification}\")\n",
    "\n",
    "# Calculate target marginals for calibration\n",
    "n_test_samples = len(y_test)\n",
    "target_marginals = recession_risk_distribution * n_test_samples\n",
    "\n",
    "print(\"\\nCalibration parameters:\")\n",
    "print(f\"  Test samples: {n_test_samples}\")\n",
    "print(f\"  Target marginals: {target_marginals}\")\n",
    "print(f\"  Sum verification: {np.sum(target_marginals):.1f} (should equal {n_test_samples})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank-Preserving Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚öñÔ∏è APPLYING RANK-PRESERVING CALIBRATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Apply calibration\n",
    "result = calibrate_dykstra(\n",
    "    P=y_proba,\n",
    "    M=target_marginals,\n",
    "    max_iters=2000,\n",
    "    tol=1e-7,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "y_proba_calibrated = result.Q\n",
    "print(\"\\n‚úÖ Calibration completed successfully!\")\n",
    "print(f\"   Converged: {result.converged}\")\n",
    "print(f\"   Iterations: {result.iterations}\")\n",
    "print(f\"   Final objective: {result.objective:.2e}\")\n",
    "\n",
    "# Verify calibration accuracy\n",
    "calibrated_marginals = np.sum(y_proba_calibrated, axis=0)\n",
    "print(\"\\nüéØ CALIBRATION VERIFICATION:\")\n",
    "print(\"Target vs Achieved marginals:\")\n",
    "for i, label in enumerate(risk_labels):\n",
    "    target = target_marginals[i]\n",
    "    achieved = calibrated_marginals[i]\n",
    "    error = abs(achieved - target)\n",
    "    print(f\"  {label}: {target:.1f} ‚Üí {achieved:.1f} (error: {error:.2e})\")\n",
    "\n",
    "max_marginal_error = np.max(np.abs(calibrated_marginals - target_marginals))\n",
    "print(f\"\\nMaximum marginal constraint violation: {max_marginal_error:.2e}\")\n",
    "\n",
    "# Check probability validity\n",
    "row_sums = np.sum(y_proba_calibrated, axis=1)\n",
    "print(\"\\nüîç PROBABILITY VALIDITY CHECK:\")\n",
    "print(f\"   Row sums range: [{np.min(row_sums):.6f}, {np.max(row_sums):.6f}]\")\n",
    "print(f\"   Max deviation from 1.0: {np.max(np.abs(row_sums - 1.0)):.2e}\")\n",
    "print(f\"   All probabilities non-negative: {np.all(y_proba_calibrated >= 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze ranking preservation\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "print(\"üìä RANKING PRESERVATION ANALYSIS\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Calculate rank correlations for each sample\n",
    "spearman_correlations = []\n",
    "for i in range(len(y_test)):\n",
    "    corr, _ = spearmanr(y_proba[i], y_proba_calibrated[i])\n",
    "    if not np.isnan(corr):  # Handle edge cases\n",
    "        spearman_correlations.append(corr)\n",
    "\n",
    "spearman_correlations = np.array(spearman_correlations)\n",
    "perfect_preservation = np.sum(np.isclose(spearman_correlations, 1.0, atol=1e-10))\n",
    "\n",
    "print(\"RANK PRESERVATION METRICS:\")\n",
    "print(f\"  Perfect rank preservation: {perfect_preservation}/{len(spearman_correlations)}\")\n",
    "print(f\"  Mean Spearman correlation: {np.mean(spearman_correlations):.6f}\")\n",
    "print(f\"  Min Spearman correlation: {np.min(spearman_correlations):.6f}\")\n",
    "\n",
    "# Prediction stability analysis\n",
    "original_predictions = np.argmax(y_proba, axis=1)\n",
    "calibrated_predictions = np.argmax(y_proba_calibrated, axis=1)\n",
    "prediction_changes = np.sum(original_predictions != calibrated_predictions)\n",
    "\n",
    "print(\"\\nPREDICTION STABILITY:\")\n",
    "print(f\"  Prediction changes: {prediction_changes}/{len(y_test)}\")\n",
    "print(f\"  Stability rate: {(1 - prediction_changes/len(y_test))*100:.1f}%\")\n",
    "\n",
    "# Show examples of changed predictions\n",
    "if prediction_changes > 0:\n",
    "    changed_indices = np.where(original_predictions != calibrated_predictions)[0]\n",
    "    print(\"  Examples of prediction changes:\")\n",
    "    for idx in changed_indices[:3]:  # Show first 3\n",
    "        orig_risk = risk_labels[original_predictions[idx]]\n",
    "        calib_risk = risk_labels[calibrated_predictions[idx]]\n",
    "        true_risk = risk_labels[y_test[idx]]\n",
    "        print(f\"    Sample {idx}: {orig_risk} ‚Üí {calib_risk} (true: {true_risk})\")\n",
    "\n",
    "# Performance comparison\n",
    "original_accuracy = accuracy_score(y_test, original_predictions)\n",
    "calibrated_accuracy = accuracy_score(y_test, calibrated_predictions)\n",
    "\n",
    "print(\"\\nPERFORMANCE COMPARISON:\")\n",
    "print(f\"  Original accuracy: {original_accuracy:.4f}\")\n",
    "print(f\"  Calibrated accuracy: {calibrated_accuracy:.4f}\")\n",
    "print(f\"  Accuracy change: {calibrated_accuracy - original_accuracy:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Risk distribution comparison\n",
    "x_pos = np.arange(3)\n",
    "width = 0.25\n",
    "\n",
    "current_dist = current_marginals\n",
    "target_dist = recession_risk_distribution\n",
    "achieved_dist = calibrated_marginals / n_test_samples\n",
    "\n",
    "axes[0, 0].bar(x_pos - width, current_dist, width, label='Original Model', alpha=0.8, color='#3498db')\n",
    "axes[0, 0].bar(x_pos, target_dist, width, label='Target (Recession)', alpha=0.8, color='#e74c3c')\n",
    "axes[0, 0].bar(x_pos + width, achieved_dist, width, label='Calibrated', alpha=0.8, color='#2ecc71')\n",
    "\n",
    "axes[0, 0].set_xlabel('Risk Class')\n",
    "axes[0, 0].set_ylabel('Probability Mass')\n",
    "axes[0, 0].set_title('Risk Distribution Comparison')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_xticks(x_pos)\n",
    "axes[0, 0].set_xticklabels(['Good', 'Moderate', 'High'])\n",
    "\n",
    "# 2. Calibration accuracy\n",
    "calibration_errors = np.abs(achieved_dist - target_dist)\n",
    "colors = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "\n",
    "bars = axes[0, 1].bar(x_pos, calibration_errors, color=colors, alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Risk Class')\n",
    "axes[0, 1].set_ylabel('Absolute Error')\n",
    "axes[0, 1].set_title('Calibration Accuracy by Risk Class')\n",
    "axes[0, 1].set_xticks(x_pos)\n",
    "axes[0, 1].set_xticklabels(['Good', 'Moderate', 'High'])\n",
    "axes[0, 1].set_yscale('log')\n",
    "\n",
    "# 3. Probability changes distribution\n",
    "prob_changes = y_proba_calibrated - y_proba\n",
    "axes[0, 2].hist(prob_changes.flatten(), bins=50, alpha=0.7, density=True, color='#9b59b6')\n",
    "axes[0, 2].axvline(0, color='black', linestyle='--', alpha=0.7)\n",
    "axes[0, 2].set_xlabel('Probability Change')\n",
    "axes[0, 2].set_ylabel('Density')\n",
    "axes[0, 2].set_title('Distribution of Probability Changes')\n",
    "\n",
    "# 4. Risk score distribution (max probability)\n",
    "max_probs_original = np.max(y_proba, axis=1)\n",
    "max_probs_calibrated = np.max(y_proba_calibrated, axis=1)\n",
    "\n",
    "axes[1, 0].hist(max_probs_original, bins=30, alpha=0.7, label='Original', density=True, color='#3498db')\n",
    "axes[1, 0].hist(max_probs_calibrated, bins=30, alpha=0.7, label='Calibrated', density=True, color='#e74c3c')\n",
    "axes[1, 0].set_xlabel('Maximum Probability (Confidence)')\n",
    "axes[1, 0].set_ylabel('Density')\n",
    "axes[1, 0].set_title('Confidence Score Distribution')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 5. Class-wise probability changes\n",
    "for i, (risk_class, color) in enumerate(zip(['Good', 'Moderate', 'High'], colors, strict=False)):\n",
    "    changes = prob_changes[:, i]\n",
    "    axes[1, 1].hist(changes, bins=30, alpha=0.6, label=f'{risk_class} Credit',\n",
    "                   color=color, density=True)\n",
    "\n",
    "axes[1, 1].axvline(0, color='black', linestyle='--', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Probability Change')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].set_title('Changes by Risk Class')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# 6. Confusion matrix comparison\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_original = confusion_matrix(y_test, original_predictions)\n",
    "cm_calibrated = confusion_matrix(y_test, calibrated_predictions)\n",
    "\n",
    "# Show difference matrix\n",
    "cm_diff = cm_calibrated - cm_original\n",
    "im = axes[1, 2].imshow(cm_diff, interpolation='nearest', cmap='RdBu',\n",
    "                      vmin=-np.max(np.abs(cm_diff)), vmax=np.max(np.abs(cm_diff)))\n",
    "axes[1, 2].set_title('Prediction Changes\\n(Calibrated - Original)')\n",
    "axes[1, 2].set_xlabel('Predicted Risk Class')\n",
    "axes[1, 2].set_ylabel('True Risk Class')\n",
    "axes[1, 2].set_xticks([0, 1, 2])\n",
    "axes[1, 2].set_xticklabels(['Good', 'Mod', 'High'])\n",
    "axes[1, 2].set_yticks([0, 1, 2])\n",
    "axes[1, 2].set_yticklabels(['Good', 'Mod', 'High'])\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar(im, ax=axes[1, 2], shrink=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Business Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive business impact analysis\n",
    "print(\"üí∞ FINANCIAL BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Portfolio parameters\n",
    "portfolio_size = 100_000  # Number of loans\n",
    "avg_loan_amount = 75_000  # Average loan size\n",
    "total_portfolio_value = portfolio_size * avg_loan_amount\n",
    "\n",
    "# Financial parameters\n",
    "interest_margin = 0.035  # 3.5% net interest margin\n",
    "loss_given_default = 0.45  # 45% loss rate on defaults\n",
    "regulatory_capital_ratio = 0.08  # 8% risk-weighted capital requirement\n",
    "\n",
    "print(\"üìä PORTFOLIO CHARACTERISTICS:\")\n",
    "print(f\"   ‚Ä¢ Portfolio size: {portfolio_size:,} loans\")\n",
    "print(f\"   ‚Ä¢ Average loan amount: ${avg_loan_amount:,}\")\n",
    "print(f\"   ‚Ä¢ Total portfolio value: ${total_portfolio_value:,.0f}\")\n",
    "print(f\"   ‚Ä¢ Net interest margin: {interest_margin:.1%}\")\n",
    "print(f\"   ‚Ä¢ Loss given default: {loss_given_default:.1%}\")\n",
    "\n",
    "# Expected loss calculations\n",
    "# Probability of default by risk class (simplified)\n",
    "pd_by_class = np.array([0.02, 0.08, 0.25])  # 2%, 8%, 25% annual default rates\n",
    "\n",
    "# Original portfolio expected losses\n",
    "original_portfolio_dist = current_marginals\n",
    "original_expected_pd = np.sum(original_portfolio_dist * pd_by_class)\n",
    "original_expected_loss = portfolio_size * avg_loan_amount * original_expected_pd * loss_given_default\n",
    "\n",
    "# Calibrated portfolio expected losses\n",
    "calibrated_portfolio_dist = achieved_dist\n",
    "calibrated_expected_pd = np.sum(calibrated_portfolio_dist * pd_by_class)\n",
    "calibrated_expected_loss = portfolio_size * avg_loan_amount * calibrated_expected_pd * loss_given_default\n",
    "\n",
    "print(\"\\nüìà EXPECTED LOSS ANALYSIS:\")\n",
    "print(f\"   ‚Ä¢ Original portfolio PD: {original_expected_pd:.2%}\")\n",
    "print(f\"   ‚Ä¢ Calibrated portfolio PD: {calibrated_expected_pd:.2%}\")\n",
    "print(f\"   ‚Ä¢ PD increase: {calibrated_expected_pd - original_expected_pd:+.2%}\")\n",
    "print(f\"   ‚Ä¢ Original expected loss: ${original_expected_loss:,.0f}\")\n",
    "print(f\"   ‚Ä¢ Calibrated expected loss: ${calibrated_expected_loss:,.0f}\")\n",
    "print(f\"   ‚Ä¢ Additional loss provision: ${calibrated_expected_loss - original_expected_loss:+,.0f}\")\n",
    "\n",
    "# Regulatory capital impact\n",
    "risk_weighted_assets_original = portfolio_size * avg_loan_amount * 0.75  # Typical RWA multiplier\n",
    "capital_requirement_original = risk_weighted_assets_original * regulatory_capital_ratio\n",
    "\n",
    "# Higher risk portfolio requires more capital\n",
    "risk_weight_increase = (calibrated_expected_pd / original_expected_pd) ** 0.5  # Simplified risk weight adjustment\n",
    "risk_weighted_assets_calibrated = risk_weighted_assets_original * risk_weight_increase\n",
    "capital_requirement_calibrated = risk_weighted_assets_calibrated * regulatory_capital_ratio\n",
    "\n",
    "additional_capital = capital_requirement_calibrated - capital_requirement_original\n",
    "cost_of_capital = 0.12  # 12% cost of equity capital\n",
    "annual_capital_cost = additional_capital * cost_of_capital\n",
    "\n",
    "print(\"\\nüè¶ REGULATORY CAPITAL IMPACT:\")\n",
    "print(f\"   ‚Ä¢ Original capital requirement: ${capital_requirement_original:,.0f}\")\n",
    "print(f\"   ‚Ä¢ Calibrated capital requirement: ${capital_requirement_calibrated:,.0f}\")\n",
    "print(f\"   ‚Ä¢ Additional capital needed: ${additional_capital:+,.0f}\")\n",
    "print(f\"   ‚Ä¢ Annual cost of additional capital: ${annual_capital_cost:,.0f}\")\n",
    "\n",
    "# CECL accounting impact\n",
    "cecl_multiplier = 1.5  # CECL typically requires 1.5x current expected losses\n",
    "cecl_provision_original = original_expected_loss * cecl_multiplier\n",
    "cecl_provision_calibrated = calibrated_expected_loss * cecl_multiplier\n",
    "cecl_impact = cecl_provision_calibrated - cecl_provision_original\n",
    "\n",
    "print(\"\\nüìã CECL ACCOUNTING IMPACT:\")\n",
    "print(f\"   ‚Ä¢ Original CECL provision: ${cecl_provision_original:,.0f}\")\n",
    "print(f\"   ‚Ä¢ Calibrated CECL provision: ${cecl_provision_calibrated:,.0f}\")\n",
    "print(f\"   ‚Ä¢ Additional CECL provision: ${cecl_impact:+,.0f}\")\n",
    "\n",
    "# Total financial impact\n",
    "total_annual_impact = annual_capital_cost + cecl_impact\n",
    "impact_as_percent_of_portfolio = total_annual_impact / total_portfolio_value * 100\n",
    "\n",
    "print(\"\\nüí∞ TOTAL FINANCIAL IMPACT:\")\n",
    "print(f\"   ‚Ä¢ Total annual financial impact: ${total_annual_impact:+,.0f}\")\n",
    "print(f\"   ‚Ä¢ Impact as % of portfolio: {impact_as_percent_of_portfolio:+.3f}%\")\n",
    "print(f\"   ‚Ä¢ Impact per loan: ${total_annual_impact / portfolio_size:+,.0f}\")\n",
    "\n",
    "# Risk management benefits\n",
    "print(\"\\n‚úÖ RISK MANAGEMENT BENEFITS:\")\n",
    "benefits = [\n",
    "    \"Accurate forward-looking loss estimates for CECL compliance\",\n",
    "    \"Better alignment with economic cycle expectations\",\n",
    "    \"Improved regulatory examination outcomes\",\n",
    "    \"Enhanced stress testing capabilities\",\n",
    "    \"More accurate pricing of credit risk\",\n",
    "    \"Better portfolio management and diversification insights\"\n",
    "]\n",
    "\n",
    "for benefit in benefits:\n",
    "    print(f\"   ‚Ä¢ {benefit}\")\n",
    "\n",
    "print(\"\\nüìä KEY PERFORMANCE INDICATORS:\")\n",
    "print(f\"   ‚Ä¢ Rank preservation: {np.mean(spearman_correlations):.6f} correlation\")\n",
    "print(f\"   ‚Ä¢ Constraint satisfaction: {max_marginal_error:.2e} max error\")\n",
    "print(f\"   ‚Ä¢ Convergence: {result.iterations} iterations\")\n",
    "print(f\"   ‚Ä¢ Prediction stability: {(1-prediction_changes/len(y_test))*100:.1f}%\")\n",
    "\n",
    "print(\"\\nüöÄ IMPLEMENTATION ROADMAP:\")\n",
    "roadmap = [\n",
    "    \"Validate calibrated model against recent economic data\",\n",
    "    \"Implement in CECL calculation engine\",\n",
    "    \"Update risk-based pricing models\",\n",
    "    \"Integrate with regulatory reporting systems\",\n",
    "    \"Establish quarterly recalibration process\",\n",
    "    \"Train risk management team on new methodology\"\n",
    "]\n",
    "\n",
    "for i, step in enumerate(roadmap, 1):\n",
    "    print(f\"   {i}. {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This example demonstrated rank-preserving calibration for financial risk assessment. The methodology applies broadly across financial services:\n",
    "\n",
    "- **CECL accounting**: Forward-looking credit loss estimation\n",
    "- **Stress testing**: Economic scenario modeling for regulatory compliance\n",
    "- **Portfolio management**: Risk-adjusted pricing and capital allocation\n",
    "- **Insurance**: Catastrophe modeling and reserve adequacy\n",
    "- **Trading**: Market risk calibration across different volatility regimes\n",
    "\n",
    "Key advantages of rank-preserving calibration in finance:\n",
    "1. Maintains credit ranking while adjusting absolute probabilities\n",
    "2. Ensures mathematical consistency with portfolio constraints\n",
    "3. Provides regulatory-compliant probability estimates\n",
    "4. Enables accurate capital requirement calculations\n",
    "\n",
    "For more examples in different domains:\n",
    "- Medical diagnosis with population health shifts\n",
    "- Text classification with domain adaptation\n",
    "- Computer vision with deployment environment changes\n",
    "- Survey reweighting for demographic representation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}